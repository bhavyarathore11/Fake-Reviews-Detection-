# Fake-Reviews-Detection

## Problem Statement
The objective of this project is to identify fake reviews from a large dataset containing various categories such as Home and Office, Sports, etc. Each review is accompanied by a rating, a label indicating whether it is computer-generated (CG) or an original human-created review (OR), and the review text itself.

The main challenge is to determine if a given review is fraudulent. Reviews generated by computers are deemed fake, while those created by humans are considered authentic.

## Description
The dataset used for this project includes 20,000 fake reviews and 20,000 genuine product reviews. Original reviews (OR) are assumed to be created by humans and are authentic, whereas computer-generated (CG) reviews are labeled as fake.

## Python Libraries and Packages Utilized
- **Numpy**: For numerical computations
- **Pandas**: For data manipulation and analysis
- **Matplotlib.pyplot**: For data visualization
- **Seaborn**: For statistical data visualization
- **Warnings**: To manage warnings
- **nltk**: For natural language processing
- **nltk.corpus**: To access text corpora
- **String**: For string operations
- **sklearn.naive_bayes**: For implementing Naive Bayes classifiers
- **sklearn.feature_extraction**: For feature extraction
- **sklearn.model_selection**: For splitting data into training and testing sets
- **sklearn.ensemble**: For ensemble methods like Random Forest
- **sklearn.tree**: For Decision Tree algorithms
- **sklearn.linear_model**: For linear models like Logistic Regression
- **sklearn.svc**: For Support Vector Classifier
- **sklearn.neighbors**: For K Nearest Neighbors algorithm

## Text Preprocessing Techniques Employed
- Removing punctuation characters
- Converting text to lowercase
- Eliminating stopwords
- Stemming words
- Lemmatizing words
- Removing digits

## Transformers Utilized for Text Vectorization and Normalization
- **CountVectorizer**: Bag of Words transformer
- **TFIDF**: Term Frequency-Inverse Document Frequency transformer

## Machine Learning Algorithms Implemented
- **Logistic Regression**
- **K Nearest Neighbors**
- **Support Vector Classifier**
- **Decision Tree Classifier**
- **Random Forests Classifier**
- **Multinomial Naive Bayes**

## Performance Summary of the Machine Learning Models
- **Logistic Regression**: Achieved a prediction accuracy of 68.86%
- **K Nearest Neighbors**: Achieved a prediction accuracy of 66.92%
- **Support Vector Machines**: Achieved a prediction accuracy of 73.1%
- **Decision Tree Classifier**: Achieved a prediction accuracy of 63.94%
- **Random Forests Classifier**: Achieved a prediction accuracy of 68.86%
- **Multinomial Naive Bayes**: Achieved a prediction accuracy of 84.63%

Among the models, the Multinomial Naive Bayes algorithm demonstrated the highest prediction accuracy for detecting fake reviews at 84.63%. The Support Vector Machines classifier also performed well with a 73.1% accuracy. Logistic Regression and Random Forests both achieved an accuracy of 68.86%. The K Nearest Neighbors algorithm predicted fake reviews with an accuracy of 66.92%, while the Decision Tree Classifier had the lowest performance, with an accuracy of 63.94%.

---
